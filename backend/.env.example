# =============================================================================
# CUPID AI - ENVIRONMENT CONFIGURATION
# =============================================================================
# Copy this file to .env and fill in your actual values
# DO NOT commit your .env file to version control!

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================
PORT=3000
FRONTEND_URL=http://localhost:5173

# =============================================================================
# JWT AUTHENTICATION
# =============================================================================
# Change this to a random secure string in production!
# Generate with: node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
JWT_SECRET=your-super-secret-jwt-key-change-this-in-production

# =============================================================================
# AI PROVIDERS - LLM CONFIGURATION
# =============================================================================
# Cupid AI uses a triple-LLM architecture:
# - Chat LLM: Generates character responses
# - Decision LLM: Makes behavioral decisions (reactions, moods, unmatch, image/voice)
# - Image Tag LLM: Generates Danbooru tags for Stable Diffusion
#
# Each LLM can use different providers
# You configure which provider/model to use per LLM in the frontend settings

# --- OpenRouter (Provider 1) ---
# Get your API key: https://openrouter.ai/
# Most users use OpenRouter for all LLMs
OPENROUTER_API_KEY=your-openrouter-api-key-here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# --- Featherless (Provider 2) ---
# Get your API key: https://featherless.ai/
# Alternative provider with vLLM backend
# Leave blank if you don't plan to use Featherless
FEATHERLESS_API_KEY=

# --- NanoGPT (Provider 3) ---
# Get your API key: https://nano-gpt.com/
# Pay-per-prompt provider with 200+ models, supports all sampling parameters
# Leave blank if you don't plan to use NanoGPT
NANOGPT_API_KEY=

# =============================================================================
# IMAGE GENERATION - STABLE DIFFUSION (OPTIONAL)
# =============================================================================
# Requires running Stable Diffusion WebUI: https://github.com/AUTOMATIC1111/stable-diffusion-webui
# Characters can send AI-generated images during conversations

# Enable/disable image generation feature
# Set to 'true' to enable, 'false' to disable
# If SD server is unavailable, images will fail gracefully and fallback to text
IMAGE_MESSAGES_ENABLED=false

# Stable Diffusion WebUI API URL
# Default port is 7860 if running locally
# Make sure to launch WebUI with --api flag
SD_SERVER_URL=http://127.0.0.1:7860

# =============================================================================
# VOICE MESSAGES - TTS (NOT YET IMPLEMENTED)
# =============================================================================
# Future feature: Characters can send voice messages
# Currently disabled - this functionality is not yet implemented
VOICE_MESSAGES_ENABLED=false
TTS_SERVER_URL=http://localhost:5000

# =============================================================================
# NOTES
# =============================================================================
# - Frontend has no .env file - all frontend config is in the UI settings pages
# - LLM model selection happens in Profile → LLM Settings (frontend)
# - Behavior settings (proactive messaging, memory, etc.) in Profile → Behavior Settings
# - SD settings (sampling, CFG, resolution) in Profile → SD Settings
# - All AI prompts are customizable in Profile → Prompts
